{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "########################################################################################################################\n",
    "# REMARKS\n",
    "########################################################################################################################\n",
    "'''\n",
    "## Coding\n",
    "- please note, this not SE course and much of the code in ML is more akin to executing workflows\n",
    "- please try to use the scripts as a documentation of yur analysis, including comments, results and interporetations\n",
    "\n",
    "## GRADING\n",
    "- Please refer to the moodle course for grading information\n",
    "\n",
    "## UPLOAD\n",
    "- upload your solution on Moodle as: \"yourLASTNAME_yourFIRSTNAME_yourMOODLE-UID___exercise_blockX.py\" </b>\n",
    "- please no non-ascii characters on last/first name :)\n",
    "- NO zipfile, NO data!, ONLY the .py file!\n",
    "\n",
    "## PRE-CODED Parts\n",
    "- all exercises might contain parts which where not yet discussed in the course\n",
    "- these sections are pre-coded then and you are encouraged to research their meaning ahead of the course\n",
    "- so, if you find something in the exercise description you havenÂ´t heard about, look at the ode section and check if this is pre-coded\n",
    "\n",
    "## ERRORS\n",
    "- when you open exercise files you'll see error (e.g. unassigned variables)\n",
    "- this is due to the fact that some parts are missing, and you should fill them in\n",
    "\n",
    "########################################################################################################################\n",
    "# IMPORTS\n",
    "########################################################################################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b5be53df68ac2c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# show all selected columns (pandas settings)\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T09:52:16.288741Z",
     "start_time": "2024-03-08T09:52:15.316341Z"
    }
   },
   "id": "3d5a22a7c7ff2e04",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "########################################################################################################################\n",
    "# PART1 // PREPARE FOR CLASSIFICATION\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "'''\n",
    "in this exercise you should prepare a dataset for applying a KNN classifier\n",
    "\n",
    "data information:\n",
    "-----------------\n",
    "- https://www.kaggle.com/andrewmvd/heart-failure-clinical-data\n",
    "\n",
    "what to do:\n",
    "------------\n",
    "- for X, use only every 2nd features (indexes 0,2,4,6,...) or any 6 features of your choice (and of course NOT the target variable y!)\n",
    "- y is the last column (\"DEATH_EVENT\")\n",
    "- X should ba a numpy array of shape (299,6), y is of shape (299,)\n",
    "\n",
    "- scale the dataset s.t. all values are between 0 and 1\n",
    "    - please note: we will talk more about scaling later in the course, here this part is pre-coded\n",
    "\n",
    "- split the dataset into a train and a test set\n",
    "    - please note: we will talk more about train/test splits later in the course\n",
    "\n",
    "- return the scaled dataframe with every 2nd feature with the corresponding names from the original dataframe\n",
    "    - your return should look like this\n",
    "        age                         float64\n",
    "        creatinine_phosphokinase    float64\n",
    "        ejection_fraction           float64\n",
    "        platelets                   float64\n",
    "        serum_sodium                float64\n",
    "        smoking                     float64\n",
    "\n",
    "- hints if you want to use a 2nd feature:\n",
    "    look into np.hstack() to combine two arrays\n",
    "    look into np.Array.reshape(-1,1) to reshape \"flat\" arrays\n",
    "    look into pd.DataFrame.astype() to change a datatype\n",
    " - hint if you want to select columns by names instead of indexes:\n",
    "    df[[]]\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51ce791d6616e778"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  creatinine_phosphokinase  ejection_fraction  platelets  \\\n",
      "0  0.636                     0.071              0.091      0.291   \n",
      "1  0.273                     1.000              0.364      0.289   \n",
      "2  0.455                     0.016              0.091      0.166   \n",
      "3  0.182                     0.011              0.091      0.224   \n",
      "4  0.455                     0.017              0.091      0.366   \n",
      "\n",
      "   serum_sodium  smoking  \n",
      "0         0.486      0.0  \n",
      "1         0.657      0.0  \n",
      "2         0.457      1.0  \n",
      "3         0.686      0.0  \n",
      "4         0.086      0.0   \n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "# -- pre-coded --\n",
    "pth = 'data_part1_part2_heartfailure.csv'\n",
    "df = pd.read_csv(pth, sep=\",\")\n",
    "\n",
    "# select X and y\n",
    "# X = every 2nd column, except of DEATH_EVENT\n",
    "X = df[df.columns[::2]].drop('DEATH_EVENT', axis=1).values\n",
    "# Y = last column (DEATH_EVENT)\n",
    "y = df['DEATH_EVENT'].values\n",
    "\n",
    "# scale ---------------------------------\n",
    "# -- pre-coded --\n",
    "mmSc = MinMaxScaler()\n",
    "mmSc.fit(X)\n",
    "X_scale = mmSc.transform(X)\n",
    "X_scale = np.round(X_scale, 3)\n",
    "\n",
    "# split the dataset into a train and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# rebuild the data frame and bind it to a variable\n",
    "solution = pd.DataFrame(X_scale, columns=df.columns[::2].drop('DEATH_EVENT'))\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "print(solution.head(), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T09:35:47.592303Z",
     "start_time": "2024-03-08T09:35:47.570865Z"
    }
   },
   "id": "af461630b465b149",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "########################################################################################################################\n",
    "# PART 2 // PREPARE FOR REGRESSION\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "'''\n",
    "in this exercise you should prepare a dataset for applying a KNN-Regressor\n",
    "\n",
    "data information:\n",
    "-----------------\n",
    "    - https://www.kaggle.com/andrewmvd/heart-failure-clinical-data\n",
    "\n",
    "what to do:\n",
    "------------\n",
    "    - y is feature \"ejection_fraction\" ... this is a numerical feature - we want to \"misuse\" the dataset for regression\n",
    "    - to obtain X drop the following columns\n",
    "        \"sex\", \"diabetes\", \"high_blood_pressure\", \"smoking\", \"anaemia\", \"DEATH_EVENT\", \"ejection_fraction\"\n",
    "    - X should be a numpy array of shape (299,6), y is of shape (299,)\n",
    "\n",
    "    - again, scale the dataset s.t. all values are between 0 and 1\n",
    "        - please note: we will talk more about scaling later in the course\n",
    "\n",
    "    - return the scaled dataframe with selected features and corresponding names from the original dataframe\n",
    "        - your return should look like this\n",
    "            age                         float64\n",
    "            creatinine_phosphokinase    float64\n",
    "            platelets                   float64\n",
    "            serum_creatinine            float64\n",
    "            serum_sodium                float64\n",
    "            time                        float64\n",
    "            ejection_fraction           float64   ... <-- this is our new y for regression!\n",
    "\n",
    "        - hints\n",
    "            look into np.hstack() to combine two arrays\n",
    "            look into np.Array.reshape(-1,1) to reshape \"flat\" arrays\n",
    "            look into pd.DataFrame.astype() to change a datatype\n",
    "\n",
    "remarks:\n",
    "--------\n",
    "    - please note that this dataset was NOT collected for a regression with ejection_fraction as target\n",
    "    - we do this here to demonstrate that\n",
    "        (1) many algorithms can perform both regression and classification\n",
    "        (2) the most important difference is \"just\" the fact that\n",
    "            --> y is continuous for regression\n",
    "            -- >and discrete for classification\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c5d54f5522b19cb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  creatinine_phosphokinase  platelets  serum_creatinine  serum_sodium  \\\n",
      "0  0.636                     0.071      0.291             0.157         0.486   \n",
      "1  0.273                     1.000      0.289             0.067         0.657   \n",
      "2  0.455                     0.016      0.166             0.090         0.457   \n",
      "3  0.182                     0.011      0.224             0.157         0.686   \n",
      "4  0.455                     0.017      0.366             0.247         0.086   \n",
      "\n",
      "    time  ejection_fraction  \n",
      "0  0.000              0.091  \n",
      "1  0.007              0.364  \n",
      "2  0.011              0.091  \n",
      "3  0.011              0.091  \n",
      "4  0.014              0.091   \n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "# -- precoded --\n",
    "pth = 'data_part1_part2_heartfailure.csv'\n",
    "df = pd.read_csv(pth, sep=\",\")\n",
    "\n",
    "# select X and y\n",
    "columns_to_drop = [\"sex\", \"diabetes\", \"high_blood_pressure\", \"smoking\", \"anaemia\", \"DEATH_EVENT\", \"ejection_fraction\"]\n",
    "X = df.drop(columns=columns_to_drop).values\n",
    "y = df['ejection_fraction'].values\n",
    "\n",
    "# scale\n",
    "# -- pre-coded --\n",
    "mmSc = MinMaxScaler()\n",
    "mmSc.fit(X)\n",
    "X_scale = mmSc.transform(X)\n",
    "X_scale = np.round(X_scale, 3)\n",
    "\n",
    "# rebuild the data frame and return\n",
    "feature_names = df.columns.drop(columns_to_drop)\n",
    "solution = pd.DataFrame(X_scale, columns=feature_names)\n",
    "\n",
    "# scale y\n",
    "mmSc_y = MinMaxScaler()\n",
    "mmSc_y.fit(y.reshape(-1, 1))\n",
    "y_scale = mmSc_y.transform(y.reshape(-1, 1))\n",
    "y_scale = np.round(y_scale, 3)\n",
    "\n",
    "# add y to the solution\n",
    "solution['ejection_fraction'] = y_scale\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "print(solution.head(), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T09:35:51.460745Z",
     "start_time": "2024-03-08T09:35:51.448047Z"
    }
   },
   "id": "1e630f197e83e20",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "########################################################################################################################\n",
    "# PART 3 // MODEL BUILDING\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "'''\n",
    "in this exercise you should use knn for regression and classification with 2 different k settings each\n",
    "\n",
    "data information:\n",
    "-----------------\n",
    "    - https://www.kaggle.com/andrewmvd/heart-failure-clinical-data\n",
    "\n",
    "what to do:\n",
    "-----------\n",
    "    classification\n",
    "        --> read dataset data_ex3_heartfailure_classification.csv\n",
    "        --> init 2 knn classifiers with k=1 and k=5\n",
    "        --> train both classifiers on the whole X array (no train test split)\n",
    "            - please note: we just do this here because data splitting was not discussed in depth until now!\n",
    "            - normally you always split your data for performance evaluation!\n",
    "        --> assemble a dataframe with the following columns\n",
    "            - y_classification ... the original target value ... int32\n",
    "            - y_hat_classification_k1 ... your predictions for k=1 (in sample predictions :( ) ... int 32\n",
    "            - y_hat_classification_k5 ... your predictions for k=5 (again, in sample predicitons :( ) ... int 32\n",
    "            - error_y_hat_classification_k1 ... 0/1, shows 1 if the classification is incorrect ... int 32\n",
    "            - error_y_hat_classification_k5 ... 0/1, shows 1 if the classification is incorrect ... int32\n",
    "\n",
    "    regression\n",
    "        --> read dataset data_ex3_heartfailure_classification.csv\n",
    "        --> init 2 knn regressors with k=3 and k=7\n",
    "        --> train both classifiers on the whole X array (no train test split)\n",
    "            - please note: we just do this here because data splitting was not discussed in depth until now!\n",
    "            - normally you always split your data for performance evaluation!\n",
    "\n",
    "        --> assemble a dataframe with the following columns\n",
    "            - y_regression ... the target value for regression ... foat64\n",
    "            - y_hat_regression_k1 ... your predictions for k=1 (in sample predictions :( ) ... float64\n",
    "            - y_hat_regression_k7 ... your predictions for k=7 (again, in sample predicitons :( ) ... float64\n",
    "            - error_y_hat_regression_k1 ... y - y_hat_regression_k1 ... float64\n",
    "            - error_y_hat_regression_k7 ... y - y_hat_regression_k7 ... float64\n",
    "\n",
    "    return the results\n",
    "        --> combine the two dataframes side by side\n",
    "        --> the result should have shape (299,10)\n",
    "        --> use th following column names .. [\"y_classification\", \"y_hat_classification_k1\", \"y_hat_classification_k5\",\n",
    "                                              \"error_y_hat_classification_k1\", \"error_y_hat_classification_k5\",\n",
    "                                              \"y_regression\", \"y_hat_regression_k1\", \"y_hat_regression_k7\",\n",
    "                                              \"error_y_hat_regression_k1\", \"error_y_hat_regression_k7\"]\n",
    "        --> the result should look like this:\n",
    "            y_classification                 float64\n",
    "            y_hat_classification_k1          float64\n",
    "            y_hat_classification_k5          float64\n",
    "            error_y_hat_classification_k1    float64\n",
    "            error_y_hat_classification_k5    float64\n",
    "            y_regression                     float64\n",
    "            y_hat_regression_k1              float64\n",
    "            y_hat_regression_k7              float64\n",
    "            error_y_hat_regression_k1        float64\n",
    "            error_y_hat_regression_k7        float64\n",
    "\n",
    "        --> all columns should be rounded to 3 decimals!\n",
    "            use np.round(array,3)\n",
    "\n",
    "        --> hints:\n",
    "            please note, after applying predict() etc you obtain flat arrays of shape (299,)\n",
    "            to build the df you can use np.vstack() (instead of hstack) and use np.Array.T afterwards (a s.c. transpose)\n",
    "            after np.vstack() you'll have (10,299) array, using .T will tilt it to (299,10)\n",
    "\n",
    "\n",
    "some questions to think about:\n",
    "------------------------------\n",
    "    - checkout the error for k = 1 on classification an regression?\n",
    "        is the result meaningful?\n",
    "        if there is anything special - why, what happened in the algorithm?\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "814bd3ad9c286d11"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y_classification  y_hat_classification_k1  y_hat_classification_k5  \\\n",
      "0               1.0                      1.0                      1.0   \n",
      "1               1.0                      1.0                      1.0   \n",
      "2               1.0                      1.0                      1.0   \n",
      "3               1.0                      1.0                      0.0   \n",
      "4               1.0                      1.0                      1.0   \n",
      "\n",
      "   error_y_hat_classification_k1  error_y_hat_classification_k5  y_regression  \\\n",
      "0                            0.0                            0.0          20.0   \n",
      "1                            0.0                            0.0          38.0   \n",
      "2                            0.0                            0.0          20.0   \n",
      "3                            0.0                            1.0          20.0   \n",
      "4                            0.0                            0.0          20.0   \n",
      "\n",
      "   y_hat_regression_k1  y_hat_regression_k7  error_y_hat_regression_k1  \\\n",
      "0                 20.0               30.714                        0.0   \n",
      "1                 38.0               33.286                        0.0   \n",
      "2                 20.0               29.000                        0.0   \n",
      "3                 20.0               31.571                        0.0   \n",
      "4                 20.0               30.000                        0.0   \n",
      "\n",
      "   error_y_hat_regression_k7  \n",
      "0                    -10.714  \n",
      "1                      4.714  \n",
      "2                     -9.000  \n",
      "3                    -11.571  \n",
      "4                    -10.000  \n"
     ]
    }
   ],
   "source": [
    "# predefined variables ------------------------\n",
    "# -- pre coded --\n",
    "solution_dataframe_columns = [\"y_classification\", \"y_hat_classification_k1\", \"y_hat_classification_k5\",\n",
    "                              \"error_y_hat_classification_k1\", \"error_y_hat_classification_k5\",\n",
    "                              \"y_regression\", \"y_hat_regression_k1\", \"y_hat_regression_k7\",\n",
    "                              \"error_y_hat_regression_k1\", \"error_y_hat_regression_k7\"]\n",
    "\n",
    "# read the data ------------------------------\n",
    "# -- pre coded --\n",
    "pth1 = 'data_part3_heartfailure_classification.csv'\n",
    "pth2 = 'data_part3_heartfailure_regression.csv'\n",
    "df_cls = pd.read_csv(pth1, sep=\";\")\n",
    "df_reg = pd.read_csv(pth2, sep=\";\")\n",
    "\n",
    "# extract X_cls, y_cls, X_reg, y_reg\n",
    "X_cls = df_cls.drop('DEATH_EVENT', axis=1).values\n",
    "y_cls = df_cls['DEATH_EVENT'].values\n",
    "X_reg = df_reg.drop('ejection_fraction', axis=1).values\n",
    "y_reg = df_reg['ejection_fraction'].values\n",
    "\n",
    "# init 4 knn models (2 for classification, 2 for regressions)\n",
    "# see docstring for details!\n",
    "# -- pre coded --\n",
    "_1nn_cls = KNeighborsClassifier(1)\n",
    "_5nn_cls = KNeighborsClassifier(5)\n",
    "_1nn_reg = KNeighborsRegressor(1)\n",
    "_7nn_reg = KNeighborsRegressor(7)\n",
    "\n",
    "# fit the models and predict\n",
    "# see docstring for details!\n",
    "# checkout the demo code for this section if you are having trouble\n",
    "_1nn_cls.fit(X_cls, y_cls)\n",
    "_5nn_cls.fit(X_cls, y_cls)\n",
    "_1nn_reg.fit(X_reg, y_reg)\n",
    "_7nn_reg.fit(X_reg, y_reg)\n",
    "\n",
    "# fit your models and predict (use variables below for prediction results)\n",
    "y_hat_classification_k1 = _1nn_cls.predict(X_cls)\n",
    "y_hat_classification_k5 = _5nn_cls.predict(X_cls)\n",
    "y_hat_regression_k1 = _1nn_reg.predict(X_reg)\n",
    "y_hat_regression_k7 = _7nn_reg.predict(X_reg)\n",
    "\n",
    "# calculate errors/mis-classifications\n",
    "# -- pre coded --\n",
    "error_y_hat_classification_k1 = y_cls != y_hat_classification_k1\n",
    "error_y_hat_classification_k5 = y_cls != y_hat_classification_k5\n",
    "error_y_hat_regression_k1 = y_reg - y_hat_regression_k1\n",
    "error_y_hat_regression_k7 = y_reg - y_hat_regression_k7\n",
    "\n",
    "# build dataframes as described above\n",
    "solution = pd.DataFrame({\n",
    "    \"y_classification\": y_cls,\n",
    "    \"y_hat_classification_k1\": y_hat_classification_k1,\n",
    "    \"y_hat_classification_k5\": y_hat_classification_k5,\n",
    "    \"error_y_hat_classification_k1\": error_y_hat_classification_k1,\n",
    "    \"error_y_hat_classification_k5\": error_y_hat_classification_k5,\n",
    "    \"y_regression\": y_reg,\n",
    "    \"y_hat_regression_k1\": y_hat_regression_k1,\n",
    "    \"y_hat_regression_k7\": y_hat_regression_k7,\n",
    "    \"error_y_hat_regression_k1\": error_y_hat_regression_k1,\n",
    "    \"error_y_hat_regression_k7\": error_y_hat_regression_k7\n",
    "}, columns=solution_dataframe_columns)\n",
    "\n",
    "# round to 3 decimals and convert to float64\n",
    "solution = solution.round(3).astype('float64')\n",
    "\n",
    "print(solution.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T09:35:57.455859Z",
     "start_time": "2024-03-08T09:35:57.410222Z"
    }
   },
   "id": "abd5f830f668e388",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "141187f62959b629"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
